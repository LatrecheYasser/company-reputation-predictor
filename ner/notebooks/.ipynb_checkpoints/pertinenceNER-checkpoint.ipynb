{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OUPUT_FORMULE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6e9f8c4e4df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSCORES_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../data/input/scores.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUPUT_FORMULE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSCORES_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OUPUT_FORMULE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPUT_FORMULE_PATH = '../data/output/secondFormule/'\n",
    "SCORES_PATH = '../data/input/scores.csv'\n",
    "import os\n",
    "os.path.exists(OUPUT_FORMULE_PATH)\n",
    "os.path.exists(SCORES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FORMULE_PATH = '../data/output/secondFormule/'\n",
    "SCORES_PATH = '../data/input/scores.csv'\n",
    "\n",
    "'''\n",
    "Proposed function to calculate the pertinence based on the three scores calculated for each ngram and theirs\n",
    "weights.\n",
    "Params:\n",
    "    sc1, sc2, sc3: The values of Score1, Score2 and Score3 after pretraitement (division of 1 by the score if \n",
    "    Score 1 or Score 3 and normalization).\n",
    "    \n",
    "    a, b, c: Weights used to ponderate the values of the scores. Where a multiplies score_1, b multiplies\n",
    "             score_2 and c multiplies score_3.\n",
    "             \n",
    "Returns: The result of the pertinence given the parameters.\n",
    "'''\n",
    "def get_pertinence(sc1, sc2, sc3, a, b, c,):\n",
    "    return a*sc1 + b*sc2 + c*sc3\n",
    "'''\n",
    "Function that does necessary pretraitment of scores of the ngrams and then computes the pertinence for each ngram\n",
    "with each combination of the passed values for the weights.\n",
    "Params:\n",
    "    data: Data-frame that contains the ngrams of the companies with their respective computed scores. It has the \n",
    "        form\n",
    "            (name, ngram, score_1, score_2, score_3)\n",
    "        \n",
    "    comb_values: Optional. It is an array-like parameter that contains the possible values that each weight could\n",
    "        have and that we want to test. Those values have to be between 0 and 1.\n",
    "Returns:\n",
    "    res: A dictionary that contains as key the combination of the weights a,b and c, in that order, and as a value\n",
    "        the a copy of the data-frame given by parameters, with the extra column 'pertinence' with the computed \n",
    "        pertinence of each ngram.\n",
    "'''\n",
    "def calc_pertinence_all(data, comb_values=[0.2, 0.4, 0.6, 0.8]):\n",
    "    df = data.copy(deep=True)\n",
    "    df['pertinence'] = 0.0\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    \n",
    "    df['score_1'] = 1/df['score_1']\n",
    "    df.loc[ df['score_1'] == float('inf'), 'score_1'] = 0\n",
    "    df['score_3'] = 1/df['score_3']\n",
    "    df.loc[ df['score_3'] == float('inf'), 'score_3'] = 2 #Maximum sinon j'aurai 1/1 donc 1, celui doit etre mieux\n",
    "    df['score_1'] = scaler.fit_transform(X=np.array(df['score_1']).reshape(-1, 1))\n",
    "    df['score_2'] = scaler.fit_transform(X=np.array(df['score_2']).reshape(-1, 1))\n",
    "    df['score_3'] = scaler.fit_transform(X=np.array(df['score_3']).reshape(-1, 1))\n",
    "    \n",
    "    values = comb_values\n",
    "    res = {}\n",
    "    for a in values:\n",
    "        for b in values:\n",
    "            for c in values:\n",
    "                centinel = 0\n",
    "                temp = df.copy(deep=True)\n",
    "                for index, row in df.iterrows():\n",
    "                    #ATENTION!Les ngrams seront penalises, mais sinon on pourra pas comparer\n",
    "                    if a+b+c == 1:\n",
    "                        centinel = 1\n",
    "                        sc1 = row['score_1']\n",
    "                        sc2 = row['score_2']\n",
    "                        sc3 = row['score_3']\n",
    "                        temp.loc[index, 'pertinence'] = get_pertinence(sc1, sc2, sc3, a, b, c)\n",
    "                if centinel != 0:\n",
    "                    res[str(a) + ',' + str(b) + ',' + str(c)] = temp\n",
    "    return res\n",
    "'''\n",
    "Function that saves a dictionary that contains dataframes in it.\n",
    "Params:\n",
    "    res: The dictionary that contains as values a dataframe object.\n",
    "Returns: Nothing. It creates one file that contains the keys of the dictionay ('keys.txt') and one csv file for\n",
    "        each dataframe, with the name composed as data_'key value'.csv.\n",
    "'''\n",
    "def saver(res):    \n",
    "    for key, val in res.items():\n",
    "        val.to_csv(OUTPUT_FORMULE_PATH + \"data_{}.csv\".format(str(key)))\n",
    "\n",
    "    with open(OUTPUT_FORMULE_PATH + 'keys.txt', 'w') as f:\n",
    "        f.write(str(list(res.keys())))\n",
    "'''\n",
    "Function that reconstructs a dictionary of dataframes that was divided into a file with the keys and\n",
    "a csv file for each dataframe of the corresponding key.\n",
    "Returns: A dictionary composed of the keys and dataframes read from files of format key.txt and \n",
    "data_'key value'.csv\n",
    "'''\n",
    "def loader():\n",
    "    with open(OUTPUT_FORMULE_PATH + 'keys.txt', 'r') as f:\n",
    "        keys = eval(f.read())\n",
    "        \n",
    "    dictex = {}\n",
    "    for key in keys:\n",
    "        dictex[key] = pd.read_csv(OUTPUT_FORMULE_PATH + \"data_{}.csv\".format(str(key)))\n",
    "    return dictex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(SCORES_PATH, sep=',', keep_default_na=False)\n",
    "res = calc_pertinence_all(scores)\n",
    "saver(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
